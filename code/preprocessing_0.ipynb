{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib\n",
    "import networkx as nx\n",
    "from scipy.sparse import *\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_stack_df(firm_and_city_df):\n",
    "    \"\"\"\n",
    "    Stack Firm columns to Firm Index\n",
    "    \"\"\"\n",
    "    firm_and_city_df = firm_and_city_df.set_index('City')\n",
    "    \n",
    "    city_count = firm_and_city_df.shape[0]\n",
    "    firm_count = firm_and_city_df.shape[1]\n",
    "    \n",
    "    stack_firm_and_city_df = firm_and_city_df.stack().reset_index()\n",
    "    stack_firm_and_city_df.columns = ['City', 'Firm', 'Size']\n",
    "    \n",
    "    return stack_firm_and_city_df\n",
    "\n",
    "def create_interlocking_world_city_network(stack_firm_and_city_df):\n",
    "    \"\"\"\n",
    "    Create interlocking world city network from stack dataframe (City,Firm,Size)\n",
    "    \"\"\"\n",
    "    \n",
    "    base_df = stack_firm_and_city_df\n",
    "\n",
    "    City_c = CategoricalDtype(sorted(base_df.City.unique()), ordered=True)\n",
    "    Firm_c = CategoricalDtype(sorted(base_df.Firm.unique()), ordered=True)\n",
    "\n",
    "    row = base_df.City.astype(City_c).cat.codes\n",
    "    col = base_df.Firm.astype(Firm_c).cat.codes\n",
    "\n",
    "    sparse_matrix = csr_matrix((base_df['Size'], (row, col)), shape=(City_c.categories.size, Firm_c.categories.size))\n",
    "    base_connectivity_matrix = sparse_matrix * sparse_matrix.transpose()\n",
    "\n",
    "    base_connectivity_matrix = tril(base_connectivity_matrix, k=-1)\n",
    "\n",
    "    co_connectivity_matrix = base_connectivity_matrix.tocoo()\n",
    "    iwcn_df = pd.DataFrame({'x_City':co_connectivity_matrix.row, 'y_City':co_connectivity_matrix.col, 'connectivity':co_connectivity_matrix.data})\n",
    "\n",
    "    city_df = pd.DataFrame({'id':range(City_c.categories.size), 'City':City_c.categories})\n",
    "    iwcn_df = iwcn_df.merge(city_df, how='left', left_on='x_City', right_on='id')\n",
    "    iwcn_df = iwcn_df.merge(city_df, how='left', left_on='y_City', right_on='id')\n",
    "\n",
    "    iwcn_df = iwcn_df.iloc[:,[2,4,6]]\n",
    "    \n",
    "    return iwcn_df\n",
    "\n",
    "def get_node_degree_centrality(iwcn_df):\n",
    "    \"\"\"\n",
    "    Return df with node degree centrality metrics for interloking world city network\n",
    "    \"\"\"\n",
    "    G = nx.from_pandas_edgelist(iwcn_df, 'City_x', 'City_y', ['connectivity'])\n",
    "\n",
    "    node_degree_centrality = G.degree(weight='connectivity')\n",
    "    \n",
    "    #save degree centrality\n",
    "    node_degree_centrality_dict = dict(node_degree_centrality)\n",
    "    node_degree_centrality_df = pd.DataFrame({'city':list(node_degree_centrality_dict.keys()), 'centrality':list(node_degree_centrality_dict.values())})\n",
    "    \n",
    "    node_degree_centrality_df['weighted_centrality'] = node_degree_centrality_df.centrality/((firm_count * 20)*city_count-1)\n",
    "\n",
    "    return node_degree_centrality_df\n",
    "\n",
    "def create_df_for_regression_model(stack_firm_and_city_df):\n",
    "    counts_of_branch_in_city_by_size = stack_firm_and_city_df.groupby('City')['Size'].value_counts().unstack().fillna(0)\n",
    "    counts_of_branch_in_firms_by_size = stack_firm_and_city_df.groupby('Firm')['Size'].value_counts().unstack().fillna(0)\n",
    "    \n",
    "    for_regression_model = stack_firm_and_city_df.merge(counts_of_branch_in_firms_by_size, how='left',on='Firm')\n",
    "    for_regression_model.columns = ['City','Firm','Size','F0','F1','F2','F3','F4','F5']\n",
    "    \n",
    "    for_regression_model = for_regression_model.merge(counts_of_branch_in_city_by_size, how='left', on='City')\n",
    "    for_regression_model.columns = ['City','Firm','Size','F0','F1','F2','F3','F4','F5','C0','C1','C2','C3','C4','C5']\n",
    "    \n",
    "    return for_regression_model\n",
    "    \n",
    "def preprocessing_pipe(firm_and_city_df, out_folder_name):\n",
    "    \"\"\"\n",
    "    Create interlocking world city network, calc node degree centrality, create file for regression model\n",
    "    \"\"\"\n",
    "    directory = '../Data/ProcessingData/{folder}'.format(folder=out_folder_name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    stack_firm_and_city_df = to_stack_df(firm_and_city_df)\n",
    "    stack_firm_and_city_df.to_csv('../Data/ProcessingData/{folder}/firm_and_city.csv'.format(folder=out_folder_name))\n",
    "    \n",
    "    iwcn_df = create_interlocking_world_city_network(stack_firm_and_city_df)\n",
    "    iwcn_df.to_csv('../Data/ProcessingData/{folder}/interlocking_world_city_network.csv'.format(folder=out_folder_name))\n",
    "    \n",
    "    node_degree_centrality_df = get_node_degree_centrality(iwcn_df)\n",
    "    node_degree_centrality_df.to_csv('../Data/ProcessingData/{folder}/node_degree_centrality.csv'.format(folder=out_folder_name))\n",
    "    \n",
    "    for_regression_model = create_df_for_regression_model(stack_firm_and_city_df)\n",
    "    for_regression_model.to_csv('../Data/ProcessingData/{folder}/for_regression_model.csv'.format(folder=out_folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "firm_and_city_18_df = pd.read_excel('../Data/RawData/raw_data_2018.xlsx','InPut')\n",
    "preprocessing_pipe(firm_and_city_18_df, 'data_2018')\n",
    "\n",
    "#2015\n",
    "firm_and_city_15_df = pd.read_excel('../Data/RawData/raw_data_2015.xlsx')\n",
    "preprocessing_pipe(firm_and_city_15_df, 'data_2015')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
